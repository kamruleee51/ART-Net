{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Detection, Segmentation, and 3D Pose Estimation of Surgical Tools Using Deep Convolutional Neural Networks and Algebraic Geometry**\n",
    "\n",
    "Article link: https://www.sciencedirect.com/science/article/abs/pii/S1361841521000402\n",
    "\n",
    "\n",
    "We present a Single Input Multiple Output Deep Convolution Neural Network(SIMO-DCNN) to get concurrent outputs, trained in an end-to-end fashion. The concurrent outputs are:\n",
    "\n",
    "&emsp; &emsp; &emsp; 1. Detection sub-network for the tool presence identification.  <br>\n",
    "&emsp; &emsp; &emsp; 2. Segmentation sub-network for getting the surgical instrument masks.  <br>\n",
    "&emsp; &emsp; &emsp; 3. Regression sub-network-1 for edgeLine (tool boundary) extraction.  <br>\n",
    "&emsp; &emsp; &emsp; 4. Regression sub-network-2 for midLine extraction. <br>\n",
    "&emsp; &emsp; &emsp; 5. Regression sub-network-3 for toolTip extraction.  <br>\n",
    "\n",
    "\n",
    "\n",
    "* This code is written by \n",
    "        ** Md. Kamrul Hasan \n",
    "        ** Medical Imaging and Applications (MAIA)\n",
    "        ** Erasmus Scholar [2017-2019] \n",
    "        ** Contact: kamruleeekuet@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bokoo/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import cv2\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.losses import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.utils import plot_model, to_categorical\n",
    "from keras.models import model_from_yaml\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np \n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import glob\n",
    "import itertools\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "from keras.initializers import Constant\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from skimage.morphology import disk\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import jaccard_similarity_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Proposed Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The implementation details with the explanation can be found on the paper. \n",
    "Please, read the paper first then see the source code.\n",
    "'''\n",
    "def SIMOCNN(nClasses, input_height, input_width):\n",
    "    \n",
    "    '''\n",
    "    Load VGG16 from keras and initialize with the ImageNet. The output of the VGG16\n",
    "    which is pool5 is used as input to all the sub-networks. This part of the network\n",
    "    is responsible for the feature extraction which is so called convolution part \n",
    "    of the semantic segmentation CNN. \n",
    "    '''\n",
    "    \n",
    "    # defining the Input shape where channel 3 means RGB.  \n",
    "    img_input = Input(shape=(input_height, input_width, 3)) \n",
    "\n",
    "    vgg_Base = VGG16(weights = 'imagenet',\n",
    "                     include_top = False,\n",
    "                     input_tensor = img_input) \n",
    "    \n",
    "    '''\n",
    "    To overcome the sub-sampling limitations  and  deconvolution  overlap, we  have\n",
    "    employed two types of skip connections. First one is between the corresponding\n",
    "    same dimensional feature map in both encoder and decoder which  has  ladder like\n",
    "    structure and  it  is  inspired  from  U-Net. Second  one, so called FrG connect\n",
    "    the very end layer of the decoder with the original image via stack of depthwise\n",
    "    separable  convolution  without sub-sampling  to  produce  the  fully resolution\n",
    "    feature map. Second skip connection is the compensatory of losing spacial \n",
    "    information dueto sub-sampling by concatenating the full resolution feature map.  \n",
    "    In the presented SIMO-DCNN network, both  the  segmentation  and  regression  \n",
    "    sub-networks  follow  our proposedencoder-decoder  networks  to  get  full  \n",
    "    resolution  features  map.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    FrG = SeparableConv2D(filters = 64,\n",
    "                          kernel_size = (3, 3), \n",
    "                          activation = 'relu',\n",
    "                          kernel_initializer='glorot_uniform',\n",
    "                          padding=\"same\")(img_input)\n",
    "    FrG = BatchNormalization()(FrG)\n",
    "    \n",
    "    FrG = SeparableConv2D(filters = 256,\n",
    "                          kernel_size = (3, 3),\n",
    "                          activation = 'relu', \n",
    "                          kernel_initializer='glorot_uniform', \n",
    "                          padding=\"same\")(FrG)\n",
    "    FrG = BatchNormalization()(FrG)\n",
    "        \n",
    "    FrG = SeparableConv2D(filters = 64,\n",
    "                          kernel_size = (3, 3), \n",
    "                          activation = 'relu',\n",
    "                          kernel_initializer='glorot_uniform',\n",
    "                          padding=\"same\")(FrG)\n",
    "    FrG = BatchNormalization()(FrG)\n",
    "    \n",
    "    FrG = SeparableConv2D(filters = nClasses,\n",
    "                          kernel_size = (3, 3), \n",
    "                          activation = 'relu',\n",
    "                          kernel_initializer='glorot_uniform',\n",
    "                          padding=\"same\")(FrG)\n",
    "    FrG = BatchNormalization()(FrG)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Decoding the encoded output to semantically project the discriminating features \n",
    "    of  lower  resolution learnt  by  the  encoder  onto  the  pixel space  of \n",
    "    higher  resolution  to  get a dense pixel wise classification.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    conv_14 = SeparableConv2D(filters = 1024, \n",
    "                            kernel_size = (3, 3), \n",
    "                            activation = 'relu', \n",
    "                            kernel_initializer='glorot_uniform', \n",
    "                            padding=\"same\")(vgg_Base.output)\n",
    "    conv_14 = BatchNormalization()(conv_14)\n",
    "\n",
    "\n",
    "    conv_15 = SeparableConv2D(filters = 1024, \n",
    "                              kernel_size = (3, 3), \n",
    "                              activation = 'relu', \n",
    "                              kernel_initializer='glorot_uniform', \n",
    "                              padding=\"same\")(conv_14)\n",
    "    conv_15 = BatchNormalization()(conv_15)\n",
    "\n",
    "    \n",
    "    deconv_1 = UpSampling2D(size = (2, 2))(conv_15)\n",
    "    deconv_1 = concatenate([vgg_Base.get_layer(name=\"block4_pool\").output,\n",
    "                            deconv_1], axis=-1)\n",
    "    deconv_1 = SeparableConv2D(filters = 512, \n",
    "                               kernel_size = (3, 3), \n",
    "                               activation = 'relu', \n",
    "                               kernel_initializer='glorot_uniform', \n",
    "                               padding = \"same\")(deconv_1)\n",
    "    deconv_1 = BatchNormalization()(deconv_1)\n",
    "\n",
    "\n",
    "    deconv_2 = UpSampling2D(size = (2, 2))(deconv_1)\n",
    "    deconv_2 = concatenate([vgg_Base.get_layer(name=\"block3_pool\").output,\n",
    "                            deconv_2], axis=-1)\n",
    "    deconv_2 = SeparableConv2D(filters = 256,\n",
    "                               kernel_size = (3, 3),\n",
    "                               activation = 'relu',\n",
    "                               kernel_initializer='glorot_uniform',\n",
    "                               padding = \"same\")(deconv_2)\n",
    "    deconv_2 = BatchNormalization()(deconv_2)\n",
    "\n",
    "\n",
    "    deconv_3 = UpSampling2D( size = (2, 2))(deconv_2)\n",
    "    deconv_3 = concatenate([vgg_Base.get_layer(name=\"block2_pool\").output,\n",
    "                            deconv_3], axis=-1)\n",
    "    deconv_3 = SeparableConv2D(filters = 128,\n",
    "                               kernel_size = (3, 3),\n",
    "                               activation = 'relu',\n",
    "                               kernel_initializer='glorot_uniform',\n",
    "                               padding = \"same\")(deconv_3)\n",
    "    kept = BatchNormalization()(deconv_3)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    '''\n",
    "    DBRS blocks named as segmentation sub-network for semantic tissue or\n",
    "    instrument pixels labelling to get semantic segmentation of the surgical tool.\n",
    "    '''\n",
    "    \n",
    "    tool = UpSampling2D(size = (2, 2))(kept)\n",
    "    tool = concatenate([vgg_Base.get_layer( name=\"block1_pool\").output, \n",
    "                        tool], axis=-1)\n",
    "    \n",
    "    tool = SeparableConv2D(filters = 64,\n",
    "                           kernel_size = (3, 3), \n",
    "                           activation = 'relu',\n",
    "                           kernel_initializer='glorot_uniform',\n",
    "                           padding = \"same\")(tool)\n",
    "    tool = BatchNormalization()(tool)\n",
    "\n",
    "    tool = UpSampling2D(size = (2, 2))(tool)\n",
    "    tool = SeparableConv2D(filters = 64, \n",
    "                           kernel_size = (3, 3), \n",
    "                           activation = 'relu',\n",
    "                           kernel_initializer='glorot_uniform', \n",
    "                           padding = \"same\")(tool)\n",
    "    tool = BatchNormalization()(tool)\n",
    "\n",
    "    tool = SeparableConv2D(filters = nClasses,\n",
    "                           kernel_size = (1, 1),\n",
    "                           activation = 'relu',\n",
    "                           kernel_initializer='glorot_uniform',\n",
    "                           padding = \"same\")(tool)\n",
    "    tool = BatchNormalization()(tool)\n",
    "\n",
    "    tool = concatenate([tool, FrG], axis=-1)\n",
    "\n",
    "    tool = Conv2D(filters = 1,\n",
    "                  kernel_size = 1,\n",
    "                  activation = 'sigmoid',\n",
    "                  name='tool')(tool)\n",
    " \n",
    "    modeltool = Model(input = img_input, output = tool)    \n",
    "    modeltool.load_weights('PreTrainedModel.hdf5')\n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    DBR blocks named as regression sub-network for mid-line feature of the surgical\n",
    "    tool for pose estimation. \n",
    "    '''\n",
    "\n",
    "    midline = UpSampling2D(size = (2, 2))(kept)\n",
    "    midline = concatenate([vgg_Base.get_layer( name=\"block1_pool\").output, \n",
    "                           midline], axis=-1)\n",
    "    \n",
    "    midline = SeparableConv2D(filters = 64,\n",
    "                              kernel_size = (3, 3),\n",
    "                              activation = 'relu',\n",
    "                              kernel_initializer='glorot_uniform',\n",
    "                              padding = \"same\")(midline)\n",
    "    midline = BatchNormalization()(midline)\n",
    "\n",
    "    midline = UpSampling2D(size = (2, 2))(midline)\n",
    "    midline = SeparableConv2D(filters = 64, \n",
    "                              kernel_size = (3, 3),activation = 'relu',\n",
    "                              kernel_initializer='glorot_uniform',\n",
    "                              padding = \"same\")(midline)\n",
    "    midline = BatchNormalization()(midline)\n",
    "\n",
    "    midline = SeparableConv2D(filters = nClasses, \n",
    "                              kernel_size = (1, 1),\n",
    "                              activation = 'relu',\n",
    "                              kernel_initializer='glorot_uniform',\n",
    "                              padding = \"same\")(midline)\n",
    "    midline = BatchNormalization()(midline)\n",
    "\n",
    "    midline = concatenate([midline, FrG], axis=-1)\n",
    "\n",
    "    midline = Conv2D(filters = 1,\n",
    "                     kernel_size = 1,\n",
    "                     activation = 'sigmoid',\n",
    "                     name='midline')(midline)\n",
    " \n",
    "    modelmidline = Model(input = img_input, output = midline)    \n",
    "    modelmidline.load_weights('PreTrainedModel.hdf5')\n",
    " \n",
    "\n",
    "\n",
    "    '''\n",
    "    DBR blocks named as regression sub-network for tool-tip feature of the surgical\n",
    "    tool for pose estimation. \n",
    "    '''\n",
    "\n",
    "    tooltip = UpSampling2D(size = (2, 2))(kept)\n",
    "    tooltip = concatenate([vgg_Base.get_layer( name=\"block1_pool\").output,\n",
    "                           tooltip], axis=-1)\n",
    "    \n",
    "    tooltip = SeparableConv2D(filters = 64,\n",
    "                              kernel_size = (3, 3),\n",
    "                              activation = 'relu',\n",
    "                              kernel_initializer='glorot_uniform',\n",
    "                              padding = \"same\")(tooltip)\n",
    "    tooltip = BatchNormalization()(tooltip)\n",
    "\n",
    "    tooltip = UpSampling2D(size = (2, 2))(tooltip)\n",
    "    tooltip = SeparableConv2D(filters = 64,\n",
    "                              kernel_size = (3, 3),\n",
    "                              activation = 'relu',\n",
    "                              kernel_initializer='glorot_uniform',\n",
    "                              padding = \"same\")(tooltip)\n",
    "    tooltip = BatchNormalization()(tooltip)\n",
    "\n",
    "    tooltip = SeparableConv2D(filters = nClasses,\n",
    "                              kernel_size = (1, 1),\n",
    "                              activation = 'relu', \n",
    "                              kernel_initializer='glorot_uniform', \n",
    "                              padding = \"same\")(tooltip)\n",
    "    tooltip = BatchNormalization()(tooltip)\n",
    "\n",
    "    tooltip = concatenate([tooltip, FrG], axis=-1)\n",
    "\n",
    "    tooltip = Conv2D(filters = 1,\n",
    "                     kernel_size = 1,\n",
    "                     activation = 'sigmoid',\n",
    "                     name='tooltip')(tooltip)\n",
    " \n",
    "    modeltooltip = Model(input = img_input, output = tooltip)    \n",
    "    modeltooltip.load_weights('PreTrainedModel.hdf5')\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    DBR blocks named as regression sub-network for Edge-line feature of the surgical\n",
    "    tool for pose estimation. \n",
    "    '''\n",
    "\n",
    "    edgeline = UpSampling2D(size = (2, 2))(kept)\n",
    "    edgeline = concatenate([vgg_Base.get_layer( name=\"block1_pool\").output,\n",
    "                            edgeline], axis=-1)\n",
    "    \n",
    "    edgeline = SeparableConv2D(filters = 64,\n",
    "                               kernel_size = (3, 3),\n",
    "                               activation = 'relu',\n",
    "                               kernel_initializer='glorot_uniform',\n",
    "                               padding = \"same\")(edgeline)\n",
    "    edgeline = BatchNormalization()(edgeline)\n",
    "\n",
    "    edgeline = UpSampling2D(size = (2, 2))(edgeline)\n",
    "    edgeline = SeparableConv2D(filters = 64,\n",
    "                               kernel_size = (3, 3),\n",
    "                               activation = 'relu',\n",
    "                               kernel_initializer='glorot_uniform',\n",
    "                               padding = \"same\")(edgeline)\n",
    "    edgeline = BatchNormalization()(edgeline)\n",
    "\n",
    "    edgeline = SeparableConv2D(filters = nClasses,\n",
    "                               kernel_size = (1, 1),\n",
    "                               activation = 'relu',\n",
    "                               kernel_initializer='glorot_uniform',\n",
    "                               padding = \"same\")(edgeline)\n",
    "    edgeline = BatchNormalization()(edgeline)\n",
    "\n",
    "    edgeline = concatenate([edgeline, FrG], axis=-1)\n",
    "\n",
    "    edgeline = Conv2D(filters = 1,\n",
    "                      kernel_size = 1,\n",
    "                      activation = 'sigmoid',name='edgeline')(edgeline)\n",
    " \n",
    "    modeledgeline = Model(input = img_input, output = edgeline)    \n",
    "    modeledgeline.load_weights('PreTrainedModel.hdf5')\n",
    "\n",
    "\n",
    "    '''\n",
    "    Detection sub-network for getting the tool flag that will indicate \n",
    "    either pose will estimate or not? \n",
    "    '''\n",
    "    x = modeltool.get_layer('block5_conv3').output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(2, activation='softmax',name='detection')(x)\n",
    "    \n",
    "    modeldetection = Model(inputs=img_input, outputs=x)\n",
    "    \n",
    "\n",
    "    '''\n",
    "    SIMO model is build by returning the multiple output as a list variable. \n",
    "    In the output prediction the sequence of the outputs are as follows:\n",
    "    \n",
    "    Output[0]= Predicted Probabilty map fo the surgical tool segmentation.\n",
    "    Output[1]= Predicted Regression map for the mid-line of the surgical tool.\n",
    "    Output[2]= Predicted Regression map for the tool-tip of the surgical tool.\n",
    "    Output[3]= Predicted Regression map for the edge-line of the surgical tool.\n",
    "    Output[4]= Predicted softmax probability of the tool detection.\n",
    "    '''\n",
    "      \n",
    "    SIMO = Model(input = img_input, output = [modeltool.output,\n",
    "                                              modelmidline.output,\n",
    "                                              modeltooltip.output,\n",
    "                                              modeledgeline.output,\n",
    "                                              modeldetection.output])\n",
    "    \n",
    "#     for layer in SIMO.layers[:40]:\n",
    "#         layer.trainable = False    \n",
    "\n",
    "    return SIMO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator function for the batch-by-batch Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def DataGenerator(data, batch_size): \n",
    "    '''\n",
    "    This function is for the data generator for fit_generator training of the SIMO\n",
    "    model. \n",
    "    Input Argument: \n",
    "          data = Is the numpy array having 6 column and N row. N is the number of \n",
    "          images as training/ testing sample. It can be pressented as below-\n",
    "          \n",
    "          orgImage | tool mask | edge-line | mid-line | tool-tip | label |\n",
    "          ---------|-----------|-----------|----------|----------|-------|\n",
    "          \n",
    "          ---------|-----------|-----------|----------|----------|-------|\n",
    "          batch_size = the number of samples that will perform forward-backward pass\n",
    "                       in a single shot.\n",
    "    Output Argument:\n",
    "        Tuple of the true images and corresponding mask/ label for each types\n",
    "        of sub-network. \n",
    "    '''\n",
    "    \n",
    "    img = np.array([i[0] for i in data]).reshape(-1,192,256,3)\n",
    "    mask = np.array([i[1] for i in data]).reshape(-1,192,256,1)\n",
    "    edge = np.array([i[2] for i in data]).reshape(-1,192,256,1)\n",
    "    mid  = np.array([i[3] for i in data]).reshape(-1,192,256,1)\n",
    "    tip = np.array([i[4] for i in data]).reshape(-1,192,256,1)\n",
    "    label = np.array([i[5] for i in data])\n",
    "    \n",
    "    label=to_categorical(label, num_classes=2, dtype='float32')\n",
    "\n",
    "    zipped = itertools.cycle( zip(img, mask, mid, edge, tip, label))\n",
    "    \n",
    "\n",
    "    while True:\n",
    "        X = [] \n",
    "        Y = []\n",
    "        Z = []\n",
    "        A = []\n",
    "        C = []   \n",
    "        D = []\n",
    "        for _ in range( batch_size):\n",
    "            im , sg, sg_mid, sg_edge, sg_tip, lab = next(zipped)\n",
    "            X.append(im)\n",
    "            Y.append(sg)\n",
    "            Z.append(sg_mid)\n",
    "            A.append(sg_edge)\n",
    "            C.append(sg_tip)\n",
    "            D.append(lab)\n",
    "            \n",
    "        yield (np.array(X) , {'tool':np.array(Y),\n",
    "                              'midline':np.array(Z),\n",
    "                              'tooltip':np.array(C),\n",
    "                              'edgeline':np.array(A),\n",
    "                              'detection':np.array(D)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoU(y_true, y_pred):\n",
    "        \n",
    "    ''' \n",
    "    The Intersection over Union (IoU) also referred to as the Jaccard index (JI),\n",
    "    is essentially a method to quantify the percent overlap between the GT mask\n",
    "    and prediction output. The IoU metric measures the number of pixels common \n",
    "    between the target and prediction masks divided by the total number of pixels\n",
    "    present across both masks.\n",
    "  \n",
    "    Input Arguments: \n",
    "        y_true: True Labels of the 2D images so called ground truth (GT).\n",
    "        y_pred: Predicted Labels of the 2D images so called Predicted/ segmented Mask.\n",
    "        \n",
    "    Output Arguments: \n",
    "\n",
    "        iou: The IoU between y_true and y_pred\n",
    "\n",
    "    Author: Md. Kamrul Hasan, \n",
    "            Erasmus Scholar on Medical Imaging and Application (MAIA)\n",
    "            E-mail: kamruleeekuet@gmail.com\n",
    "\n",
    "    '''\n",
    "    \n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (intersection) / (K.sum(y_true_f) + K.sum(y_pred_f)-intersection)\n",
    "\n",
    "\n",
    "def IoU_loss(y_true, y_pred):\n",
    "    return 1-IoU(y_true, y_pred)\n",
    "\n",
    "\n",
    "def bce_IoU_loss(y_true, y_pred):\n",
    "    return (binary_crossentropy(y_true, y_pred) + IoU_loss(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the whole SIMO end-to-end fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bokoo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:161: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"to...)`\n",
      "/home/bokoo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:203: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"mi...)`\n",
      "/home/bokoo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:246: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"to...)`\n",
      "/home/bokoo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:287: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ed...)`\n",
      "/home/bokoo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:319: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=[<tf.Tenso...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 192, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 192, 256, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 192, 256, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 96, 128, 64)  0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 96, 128, 128) 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 96, 128, 128) 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 48, 64, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 48, 64, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 48, 64, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 48, 64, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 24, 32, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 24, 32, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 24, 32, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 24, 32, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 12, 16, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 12, 16, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 12, 16, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 12, 16, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 6, 8, 512)    0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_5 (SeparableCo (None, 6, 8, 1024)   529920      block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 6, 8, 1024)   4096        separable_conv2d_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_6 (SeparableCo (None, 6, 8, 1024)   1058816     batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 6, 8, 1024)   4096        separable_conv2d_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 12, 16, 1024) 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 12, 16, 1536) 0           block4_pool[0][0]                \n",
      "                                                                 up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_7 (SeparableCo (None, 12, 16, 512)  800768      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 12, 16, 512)  2048        separable_conv2d_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 24, 32, 512)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 24, 32, 768)  0           block3_pool[0][0]                \n",
      "                                                                 up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_8 (SeparableCo (None, 24, 32, 256)  203776      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 24, 32, 256)  1024        separable_conv2d_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 48, 64, 256)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 48, 64, 384)  0           block2_pool[0][0]                \n",
      "                                                                 up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_9 (SeparableCo (None, 48, 64, 128)  52736       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 48, 64, 128)  512         separable_conv2d_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 96, 128, 128) 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2D)  (None, 96, 128, 128) 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2D)  (None, 96, 128, 128) 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_10 (UpSampling2D) (None, 96, 128, 128) 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 96, 128, 192) 0           block1_pool[0][0]                \n",
      "                                                                 up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_1 (SeparableCo (None, 192, 256, 64) 283         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 96, 128, 192) 0           block1_pool[0][0]                \n",
      "                                                                 up_sampling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 96, 128, 192) 0           block1_pool[0][0]                \n",
      "                                                                 up_sampling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 96, 128, 192) 0           block1_pool[0][0]                \n",
      "                                                                 up_sampling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_10 (SeparableC (None, 96, 128, 64)  14080       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 192, 256, 64) 256         separable_conv2d_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_13 (SeparableC (None, 96, 128, 64)  14080       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_16 (SeparableC (None, 96, 128, 64)  14080       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_19 (SeparableC (None, 96, 128, 64)  14080       concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 96, 128, 64)  256         separable_conv2d_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2 (SeparableCo (None, 192, 256, 256 17216       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 96, 128, 64)  256         separable_conv2d_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 96, 128, 64)  256         separable_conv2d_16[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 96, 128, 64)  256         separable_conv2d_19[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 192, 256, 64) 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 192, 256, 256 1024        separable_conv2d_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2D)  (None, 192, 256, 64) 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_9 (UpSampling2D)  (None, 192, 256, 64) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_11 (UpSampling2D) (None, 192, 256, 64) 0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_11 (SeparableC (None, 192, 256, 64) 4736        up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_3 (SeparableCo (None, 192, 256, 64) 18752       batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_14 (SeparableC (None, 192, 256, 64) 4736        up_sampling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_17 (SeparableC (None, 192, 256, 64) 4736        up_sampling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_20 (SeparableC (None, 192, 256, 64) 4736        up_sampling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 192, 256, 64) 256         separable_conv2d_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 192, 256, 64) 256         separable_conv2d_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 192, 256, 64) 256         separable_conv2d_14[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 192, 256, 64) 256         separable_conv2d_17[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 192, 256, 64) 256         separable_conv2d_20[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_12 (SeparableC (None, 192, 256, 2)  194         batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_4 (SeparableCo (None, 192, 256, 2)  706         batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_15 (SeparableC (None, 192, 256, 2)  194         batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_18 (SeparableC (None, 192, 256, 2)  194         batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_21 (SeparableC (None, 192, 256, 2)  194         batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 512)          0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 192, 256, 2)  8           separable_conv2d_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 192, 256, 2)  8           separable_conv2d_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 192, 256, 2)  8           separable_conv2d_15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 192, 256, 2)  8           separable_conv2d_18[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 192, 256, 2)  8           separable_conv2d_21[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          131328      global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 192, 256, 4)  0           batch_normalization_12[0][0]     \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 192, 256, 4)  0           batch_normalization_15[0][0]     \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 192, 256, 4)  0           batch_normalization_18[0][0]     \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 192, 256, 4)  0           batch_normalization_21[0][0]     \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tool (Conv2D)                   (None, 192, 256, 1)  5           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "midline (Conv2D)                (None, 192, 256, 1)  5           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tooltip (Conv2D)                (None, 192, 256, 1)  5           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "edgeline (Conv2D)               (None, 192, 256, 1)  5           concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "detection (Dense)               (None, 2)            514         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 17,620,963\n",
      "Trainable params: 17,613,263\n",
      "Non-trainable params: 7,700\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "CurrentDirectory=os.getcwd()\n",
    "\n",
    "\n",
    "datatrain = np.load(CurrentDirectory+'/training_data.npy')\n",
    "TrainGen = DataGenerator(data= datatrain, batch_size=5)\n",
    "\n",
    "\n",
    "datatest = np.load(CurrentDirectory+'/testing_data.npy')\n",
    "TestGen = DataGenerator(data= datatest, batch_size=5)\n",
    "\n",
    "\n",
    "model = SIMOCNN(2, 192, 256)\n",
    "\n",
    "\n",
    "plot_model(model, show_shapes=True, to_file='Graph of ART-Net.png')\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.compile(optimizer = 'adadelta', \n",
    "              loss = {'tool':bce_IoU_loss,\n",
    "                      'midline':'mean_squared_error',\n",
    "                      'tooltip':'mean_squared_error',\n",
    "                      'edgeline':'mean_squared_error',\n",
    "                      'detection':'categorical_crossentropy',}, \n",
    "              metrics = {'tool': IoU,\n",
    "                         'midline':'mae',\n",
    "                         'tooltip':'mae',\n",
    "                         'edgeline':'mae',\n",
    "                         'detection': 'acc'})\n",
    "\n",
    "model_checkpoint = ModelCheckpoint('FineTunedmodel.hdf5', \n",
    "                                   monitor='val_loss', \n",
    "                                   verbose=1, \n",
    "                                   save_best_only=True)\n",
    "\n",
    "\n",
    "\n",
    "model_yaml = model.to_yaml()\n",
    "with open('modelSaved.yaml', \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "\n",
    "# history=model.fit_generator(TrainGen, \n",
    "#                             steps_per_epoch=133, \n",
    "#                             epochs=250,\n",
    "#                             verbose=1, \n",
    "#                             validation_data= TestGen, \n",
    "#                             validation_steps=31,\n",
    "#                             callbacks=[model_checkpoint],\n",
    "#                             use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the training and testing performance of the SIMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot training & validation loss values\n",
    "# plt.figure()\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('Model loss Total')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train_total','val_total'], loc='upper right')\n",
    "# plt.grid('on')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(history.history['tool_loss'])\n",
    "# plt.plot(history.history['val_tool_loss'])\n",
    "# plt.title('Model loss for the Tool Segmentation')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train_tool_loss', 'val_tool_loss'], loc='upper right')\n",
    "# plt.grid('on')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(history.history['midline_loss'])\n",
    "# plt.plot(history.history['val_midline_loss'])\n",
    "# plt.title('Model loss for the Midline line prediction')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train_midline_loss','val_midline_loss'], loc='upper right')\n",
    "# plt.grid('on')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(history.history['tooltip_loss'])\n",
    "# plt.plot(history.history['val_tooltip_loss'])\n",
    "# plt.title('Model loss for the tool tip point prediction')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train_tooltip_loss','val_tooltip_loss'], loc='upper right')\n",
    "# plt.grid('on')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(history.history['edgeline_loss'])\n",
    "# plt.plot(history.history['val_edgeline_loss'])\n",
    "# plt.title('Model loss for the edge line prediction')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train_edgeLine_loss','val_edgeLine_loss'], loc='upper right')\n",
    "# plt.grid('on')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(history.history['detection_loss'])\n",
    "# plt.plot(history.history['val_detection_loss'])\n",
    "# plt.title('Model loss for the detection ')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train_detection_loss','val_detection_loss'], loc='upper right')\n",
    "# plt.grid('on')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
